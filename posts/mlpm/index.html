<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Fang">
<meta name="dcterms.date" content="2022-11-17">
<meta name="description" content="Learn how to use linear regression for multiclass classification, and why doing sort of works but is not a good idea.">

<title>Don‚Äôt use linear regression for multiclass classification - Problems with the Multinomial Linear Probability Model ‚Äì Christian Fang</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-15ea27bac76f9890c21e80949f497921.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8143d892e0ed555d9c4932a0b7ddc6cd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Don‚Äôt use linear regression for multiclass classification - Problems with the Multinomial Linear Probability Model ‚Äì Christian Fang">
<meta property="og:description" content="Learn how to use linear regression for multiclass classification, and why doing sort of works but is not a good idea.">
<meta property="og:image" content="https://www.christianfang.eu/posts/mlpm/mlpm.png">
<meta property="og:site_name" content="Christian Fang">
<meta property="og:image:height" content="480">
<meta property="og:image:width" content="567">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Christian Fang</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../contact.html"> 
<span class="menu-text">Contact</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools tools-wide">
    <a href="https://github.com/christianfang95/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
    <a href="https://www.linkedin.com/in/fangchris95/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
    <a href="https://scholar.google.de/citations?user=FePrRkEAAAAJ" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-bank2"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Don‚Äôt use linear regression for multiclass classification - Problems with the Multinomial Linear Probability Model</h1>
                  <div>
        <div class="description">
          Learn how to use linear regression for multiclass classification, and why doing sort of works but is not a good idea.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">statistics</div>
                <div class="quarto-category">LPM</div>
                <div class="quarto-category">regression</div>
                <div class="quarto-category">Python</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Christian Fang </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 17, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul>
  <li><a href="#inventing-anna-the-multinomial-linear-probability-model-mlpm" id="toc-inventing-anna-the-multinomial-linear-probability-model-mlpm" class="nav-link" data-scroll-target="#inventing-anna-the-multinomial-linear-probability-model-mlpm">Inventing <del>Anna</del> the multinomial linear probability model (MLPM)</a></li>
  </ul></li>
  <li><a href="#how-does-it-work" id="toc-how-does-it-work" class="nav-link" data-scroll-target="#how-does-it-work">(How) does it work?</a>
  <ul>
  <li><a href="#importing-packages-and-simulating-data" id="toc-importing-packages-and-simulating-data" class="nav-link" data-scroll-target="#importing-packages-and-simulating-data">Importing packages and simulating data</a></li>
  <li><a href="#implementing-the-mlpm" id="toc-implementing-the-mlpm" class="nav-link" data-scroll-target="#implementing-the-mlpm">Implementing the MLPM</a></li>
  <li><a href="#implementing-relevant-baselines-multinomial-logistic-regression-and-k-nearest-neighbors" id="toc-implementing-relevant-baselines-multinomial-logistic-regression-and-k-nearest-neighbors" class="nav-link" data-scroll-target="#implementing-relevant-baselines-multinomial-logistic-regression-and-k-nearest-neighbors">Implementing relevant baselines: multinomial logistic regression and K-nearest neighbors</a></li>
  <li><a href="#plotting-the-results" id="toc-plotting-the-results" class="nav-link" data-scroll-target="#plotting-the-results">Plotting the results</a></li>
  </ul></li>
  <li><a href="#the-result-how-well-does-the-mlpm-perform" id="toc-the-result-how-well-does-the-mlpm-perform" class="nav-link" data-scroll-target="#the-result-how-well-does-the-mlpm-perform">The result: how well does the MLPM perform?</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In the second edition of ‚ÄúAn Introduction to Statistical Learning‚Äù, James, Witten, Hastie, and Tibshirani outline why it is a bad idea to use linear regression for a multiclass classification task <a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf">(see pg. 131)</a>. In short, the linear regression coefficients and predicted probabilities are dependent on the ordering of the classes.</p>
<p>Suppose we want to predict whether someone likes Britney Spears, Taylor Swift, or Cher. If we define the outcome/target variable as follows:</p>
<p><span class="math display">  Y =
  \begin{cases}
    0: Britney \\
    1: Taylor \\
    2: Cher
  \end{cases} </span></p>
<p>and run a linear regression, the coefficients for the predictors mean something completely different compared to if we simply reorder the classes, for example like this:</p>
<p><span class="math display">  Y =
  \begin{cases}
    0: Taylor \\
    1: Cher \\
    2: Britney
  \end{cases} </span></p>
<p>Furthermore, linear regression assumes that the difference between the classes is equally big (which makes absolutely no sense when you talk about a qualitative target variable).</p>
<p>On the other hand, James et al.&nbsp;also mention that using linear regression for a <em>binary</em> classification task is generally not all that problematic, though the authors rightly conclude that such an approach is still undesirable for many reasons, for example because you can get nonsensical predicted probabilities such as -0.2 or 1.5. What James et al.&nbsp;don‚Äôt mention is that using linear regression on a binary dependent variable <em>is</em> considered a valid approach by (mostly/only) economists and sociologists, who refer to such a model as a ‚Äúlinear probability model‚Äù or LPM. I have <a href="../../posts/interactions/">written about the LPM before</a> and I generally do not think that the LPM makes sense or should be used. However, I hadn‚Äôt really thought of using LPMs for classification tasks.</p>
<p>That gave me an idea: can‚Äôt we simply decompose a multiclass classification problem into a series of LPMs? Would it work, as in: would the prediction performance be at least reasonably high to warrant the use of such a model? After all, estimating a series of LPMs is sort of the same thing as approximating a multinomial logistic regression model by fitting a series of binary logistic regressions.</p>
<p>Note: <em>This model is meant to be a joke (literally). As you will see from my conclusion, I do not recommend using the MLPM as a classification algorithm. You should also not use the LPM‚Ä¶ Also note that the example of liking either Britney, Taylor, or Cher is completely ridiculous. Of course you should like all of them!</em></p>
<p>You can find the code also on <a href="https://github.com/christianfang95/modelsfromscratch/blob/175f2b8f0fc794248b5f2d9947ab99167e29d6d7/mlpm/mlpm.py">GitHub</a>.</p>
<section id="inventing-anna-the-multinomial-linear-probability-model-mlpm" class="level2">
<h2 class="anchored" data-anchor-id="inventing-anna-the-multinomial-linear-probability-model-mlpm">Inventing <del>Anna</del> the multinomial linear probability model (MLPM)</h2>
<p>The ‚Äúmultinomial linear probability model‚Äù is not actually a proper statistical model, it is just a series separate ‚Äúbinary‚Äù LPMs put together. I am not 100% sure about the mathematical formula for the MLPM (since I just made it up and the model doesn‚Äôt really make sense), but I guess it should be something like this (correct me if I‚Äôm wrong!):</p>
<p><span class="math display">Pr(Y_{i} = k) = \alpha + \sum_{j=1}^{k} \beta_{k}X_{i}</span></p>
<p>In other words, if we have <span class="math inline">k</span> classes to predict, we fit <span class="math inline">k</span> separate binary LPMs. For example, if we have three classes, [0, 1, 2] (e.g., liking Taylor, Britney, or Cher), then we would simply fit three LPMs:</p>
<p><span class="math display">Pr(Y_{i} = 0) = \alpha + \sum \beta_{i}X_{i}</span></p>
<p><span class="math display">Pr(Y_{i} = 1) = \alpha + \sum \beta_{i}X_{i}</span></p>
<p><span class="math display">Pr(Y_{i} = 2) = \alpha + \sum \beta_{i}X_{i}</span></p>
<p>This gives us three predicted probabilities:</p>
<ul>
<li>the probability of the observation being in class 0 (as opposed to 1 and 2) (e.g., liking Britney vs.&nbsp;Taylor and Cher)</li>
<li>the probability of the observation being in class 1 (as opposed to 0 and 2) (e.g., liking Taylor vs.&nbsp;Britney and Cher)</li>
<li>the probability of the observation being in class 2 (as opposed to 0 and 1) (e.g., liking Cher vs.&nbsp;Taylor and Britney)</li>
</ul>
<p>My intuition told me that this is a deeply weird approach. As described above, the problem with the LPM is that it can yield predicted probabilities outside the interval [0,1]. This is not the case when using a model that explicitly places constraints on the range of the predicted probabilities, such as (multinomial) logistic regression. In case of, for example, multinomial logistic regression, the sum of the predicted probabilities will always be 1 as multinomial logistic regression models a joint probability distribution for all outcomes. In case of the MLPM, just like with the regular ‚Äúbinary‚Äù LPM, there are no constraints on the range of the predicted probabilities, which implies that there is the potential for</p>
<p><span class="math display">\sum_{j=1}^{k} Pr(Y_{i} = k) ‚â† 1</span></p>
<p>This obviously doesn‚Äôt make sense. The sum of predicted probabilities cannot be greater or smaller than 1. I assumed that this fundamental flaw of the ‚ÄúMLPM‚Äù would make it a poor classifier.</p>
<p>Little did I know‚Ä¶</p>
</section>
</section>
<section id="how-does-it-work" class="level1">
<h1>(How) does it work?</h1>
<p>There are multiple ways of estimating an ‚ÄúMLPM‚Äù. One way would be to create dummy variables for the target variable, fit <span class="math inline">k</span> LPMs and calculate the <span class="math inline">k</span> predicted probabilities.</p>
<p>An easier way is to use the <code>OneVsRestClassifier</code> from <code>sklearn.multiclass</code>, which breaks down a multiclass classification problem into a series of binary classification tasks. Usually, you would use it with a logistic regression, but we can simply use a linear regression model instead.</p>
<p>To assess the extent to which the MLPM ‚Äúworks‚Äù as a classification algorithm, I will calculate and plot the F1 scores for all models (indivually per class and averaged). The F1 score is the harmonic mean of precision and recall, and is commonly used to compare the performance of different classifiers. F1 ranges from 0 (bad) to 1 (perfect). So, the higher the F1, the better.</p>
<section id="importing-packages-and-simulating-data" class="level2">
<h2 class="anchored" data-anchor-id="importing-packages-and-simulating-data">Importing packages and simulating data</h2>
<p>First, let‚Äôs import the required packages and define a function that simulates our data.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Import required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.multiclass <span class="im">import</span> OneVsRestClassifier</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, LogisticRegression</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>I specify the target to have 3 classes (0: liking Britney, 1: liking Taylor, 2: liking Cher), 1000 observations, and a total of 10 features. Furthermore, I split the data into a training and a testing data set. This is not strictly necessary in our case, but it‚Äôs always good to check if our model can generalize to unseen data.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_data(classes <span class="op">=</span> <span class="dv">3</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  X, y <span class="op">=</span> make_classification(n_samples <span class="op">=</span> <span class="dv">1000</span>, </span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>                             n_features <span class="op">=</span> <span class="dv">10</span>, </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>                             n_informative <span class="op">=</span> <span class="dv">3</span>, </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>                             n_redundant <span class="op">=</span> <span class="dv">7</span>, </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                             n_classes <span class="op">=</span> classes, </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                             random_state <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size <span class="op">=</span> <span class="fl">0.20</span>, random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span>(X_train, X_test, y_train, y_test)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="implementing-the-mlpm" class="level2">
<h2 class="anchored" data-anchor-id="implementing-the-mlpm">Implementing the MLPM</h2>
<p>Next, we implement our state-of-the-art MLPM by passing <code>LinearRegression()</code> from <code>sklearn.linear_model</code> to the <code>OneVsRestClassifier</code>. We, then, calculate the predicted proabilities and get the <code>classification_report</code> as a Pandas data frame. The <code>classification_report</code> here simply picks the highest predicted probability as the predicted value.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mlpm(X_train, X_test, y_train, y_test):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""This function fits multinomial linear probability models on the test data, </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">  and gets predictions for the training data</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  lpm <span class="op">=</span> OneVsRestClassifier(LinearRegression()).fit(X_train, y_train)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> lpm.predict(X_test)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  lpm_report <span class="op">=</span> classification_report(y_test, y_pred, output_dict <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  lpm_report <span class="op">=</span> pd.DataFrame(lpm_report).transpose()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> lpm_report</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="implementing-relevant-baselines-multinomial-logistic-regression-and-k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="implementing-relevant-baselines-multinomial-logistic-regression-and-k-nearest-neighbors">Implementing relevant baselines: multinomial logistic regression and K-nearest neighbors</h2>
<p>To gauge the performance of the MLPM, I implemented two ‚Äúoutdated‚Äù alternatives to the MLPM (‚Äúoutdated‚Äù as the MLPM is super novel, from 2022 üòè), namely multinomial logistic regression and K nearest neighbors. Multinomial logistic regression is an extension of logistic regression (a parametric supervised learning algorithm), and K nearest neighbors (a non-parametric supervised learning method).</p>
<p>I defined two functions for multinomial logistic regression and KNN, respecitively:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Create multnomial logistic regression</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multinom(X_train, X_test, y_train, y_test):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""This function fits multinomial logistic regression on the test data, </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">  and gets predictions for the training data</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  multinom <span class="op">=</span> OneVsRestClassifier(LogisticRegression(multi_class <span class="op">=</span> <span class="st">"multinomial"</span>)).fit(X_train, y_train)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> multinom.predict(X_test)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  multinom_report <span class="op">=</span> classification_report(y_test, y_pred, output_dict <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  multinom_report <span class="op">=</span> pd.DataFrame(multinom_report).transpose()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> multinom_report</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Create KNN Classifier</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> knn(X_train, X_test, y_train, y_test, classes):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""This function fits KNN on the test data, </span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">  and gets predictions for the training data</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  knn <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> classes)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>  knn.fit(X_train, y_train)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>  y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  knn_report <span class="op">=</span> classification_report(y_test, y_pred, output_dict <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>  knn_report <span class="op">=</span> pd.DataFrame(knn_report).transpose()</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> knn_report</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="plotting-the-results" class="level2">
<h2 class="anchored" data-anchor-id="plotting-the-results">Plotting the results</h2>
<p>Lastly, I define a function to plot the results and wrap all previous functions in a main function:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot(lpm, log, knn):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a> <span class="co">"""This function plots the F1 scores per class and averaged for all three models"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a> fig, ax <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a> fig.suptitle(<span class="st">'F1 scores of multinomial regressions and KNN'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a> <span class="co">#Set line style and line width</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a> ls <span class="op">=</span> <span class="st">"-"</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a> lw <span class="op">=</span> <span class="fl">2.5</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a> <span class="co">#Add lines for the 3 models</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a> plt.plot(knn.index[:<span class="op">-</span><span class="dv">2</span>], knn[<span class="st">'f1-score'</span>][<span class="dv">0</span>:<span class="dv">4</span>], marker <span class="op">=</span> <span class="st">'o'</span>, color <span class="op">=</span> <span class="st">'g'</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>             linewidth<span class="op">=</span>lw, linestyle<span class="op">=</span>ls)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a> plt.plot(log.index[:<span class="op">-</span><span class="dv">2</span>], log[<span class="st">'f1-score'</span>][<span class="dv">0</span>:<span class="dv">4</span>], marker <span class="op">=</span> <span class="st">'o'</span>, color <span class="op">=</span> <span class="st">'b'</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>             linewidth<span class="op">=</span>lw, linestyle<span class="op">=</span>ls)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a> plt.plot(lpm.index[:<span class="op">-</span><span class="dv">2</span>], lpm[<span class="st">'f1-score'</span>][<span class="dv">0</span>:<span class="dv">4</span>], marker <span class="op">=</span> <span class="st">'o'</span>, color <span class="op">=</span> <span class="st">'r'</span>, </span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>             linewidth<span class="op">=</span>lw, linestyle<span class="op">=</span>ls)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a> <span class="co">#Set axes title, label, and legend</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a> ax.set_ylabel(<span class="st">'F1 score'</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a> ax.set_xlabel(<span class="st">'Class'</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a> ax.legend((<span class="st">'KNN'</span>, <span class="st">'multinomial </span><span class="ch">\n</span><span class="st">logistic regression'</span>, <span class="st">'MLPM'</span>))</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a> <span class="co">#Plot formatting</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a> plt.xticks([<span class="st">'0'</span>, <span class="st">'1'</span>, <span class="st">'2'</span>, <span class="st">'accuracy'</span>], [<span class="st">'Britney'</span>, <span class="st">'Taylor'</span>, <span class="st">'Cher'</span>, <span class="st">'mean'</span>])</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a> plt.ylim([<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a> plt.show()</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main():</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a> <span class="co">"""This function calculates the three models and plots the results"""</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a> classes <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a> X_train, X_test, y_train, y_test <span class="op">=</span> simulate_data(classes <span class="op">=</span> classes)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a> mod1 <span class="op">=</span> mlpm(X_train, X_test, y_train, y_test)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a> mod2 <span class="op">=</span> multinom(X_train, X_test, y_train, y_test)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a> mod3 <span class="op">=</span> knn(X_train, X_test, y_train, y_test, classes <span class="op">=</span> classes)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a> plot(mod1, mod2, mod3)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a> plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
</section>
<section id="the-result-how-well-does-the-mlpm-perform" class="level1">
<h1>The result: how well does the MLPM perform?</h1>
<p>Now, all there is left to do is to call our main function and examine the resulting plot showing the F1 scores of the three models:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>main()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><img src="mlpm.png" class="img-fluid"></p>
<p>The plot shows us that - perhaps shockingly enough - the MLPM does not perform all that terribly. It is only slightly worse than multinomial logistic regression, though when compared to KNN, both the MLPM and multinomial logistic regression don‚Äôt perform well.</p>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>Well, I guess the MLPM sort of works for multiclass classification tasks. In hindsight, this is perhaps unsurprising, as multinomial logistic regression also uses a linear predictor function under the hood. The lower F1 scores for the MLPM might be the result of comparatively more incorrect classifications due to nonsensical predicted probabilities.</p>
<p>Does this mean you should use the MLPM? I don‚Äôt really think so. The MLPM does not make substantive sense, as out-of-range predicted probabilities are just not useful and it is doubtful if any of the parameter estimates make sense or have valid statistical properties. Also, a vanilla multinomial logistic regression (which does not give us problems like nonsense predicted probabilities) performs better, and KNN (and probably many other classification algorithms) beats both. So, why bother?</p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{fang2022,
  author = {Fang, Christian},
  title = {Don‚Äôt Use Linear Regression for Multiclass Classification -
    {Problems} with the {Multinomial} {Linear} {Probability} {Model}},
  date = {2022-11-17},
  url = {https://www.christianfang.eu/posts/mlpm/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-fang2022" class="csl-entry quarto-appendix-citeas" role="listitem">
Fang, Christian. 2022. <span>‚ÄúDon‚Äôt Use Linear Regression for Multiclass
Classification - Problems with the Multinomial Linear Probability
Model.‚Äù</span> November 17, 2022. <a href="https://www.christianfang.eu/posts/mlpm/">https://www.christianfang.eu/posts/mlpm/</a>.
</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/www\.christianfang\.eu\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>