<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>You probably know that statistical and machine learning methods are are based on a lot of math. So. much. math. For example, we can prove mathematically that OLS estimates \(\hat\beta\) - provided all of the Gauss-Markov assumptions are met - will in the long run converge to the true population parameters \(\beta\).</p> <p>But what if you do not want to do the math and you still want to test if a given statistical model “works” in a specific situation? Enter simulation studies. In a simulation study, we effectively choose the truth (the so called ground truth) and can test if estimate from our statistical model of choice in the long run converge to that ground truth. We do this by simulating data following from the ground truth we specify, run the model on it, and examine how close the model estimates are to our ground truth. We repeat this process usually thousands of times to get a good idea of how a model behaves “on average” or “in the long run”.</p> <p>This sounds complicated, but is thankfully very straightforward to implement. If you are like me, soon enough you might find yourself running simulations every time you encounter a new statistical model because you just want to see what the heck it does :)</p> <h1 id="basic-workflow-of-a-simulation-study">Basic workflow of a simulation study</h1> <p>The basic workflow of a simulation study is pretty easy.</p> <ol> <li>First, we simulate our data given a ground truth using a random number simulator.</li> <li>Second, run the models we are interested in, on the data we generated in step 1 and store the parameters we are interested in (e.g., regression coefficients, p-values, accuracy…)</li> <li>Third, we repeat this a large number of times (say, 10.000 times).</li> </ol> <p>This is it.</p> <h1 id="a-toy-example-linear-regression-vs-t-test">A toy example: linear regression vs. t-test.</h1> <p>Suppose we are interested in testing who makes more money: data scientist or data engineers. But we are unsure whether we should use a linear regression or an independent sample t-test. We have a hunch that we should use linear regression. In other words: we want to test if a t-test just as good as recovering the ground truth than a linear regression.</p> <h2 id="defining-the-data">Defining the data</h2> <p>For this example, let’s suppose that we want to simulate data based on the following equation:</p> \[income = 50000 + 10000 * data engineer + e(\mu=1, \sigma=0)\] <p>In other words, we assume that the outcome (income) is defined as a linear combination of the intercept term (50), 10 \(\*\) data engineer, and normally distributed error term. This ground truth can be interpreted in the following ways: data scientists on average make 50k a year, and data engineers make 10k more than data scientists. Why do we add an error term here? Several reasons, but the main one is that simulations are supposed to approximate “real life”, and in real life there’s always some part of the variation of the outcome we can’t explain due to completely random processes.</p> <p>We translate this ground truth into the following R code:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">make_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">sample_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10000</span><span class="p">,</span><span class="w"> 
                          </span><span class="n">intercept</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w"> 
                          </span><span class="n">beta_1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">data_engineer</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rbinom</span><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample_size</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">prob</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.5</span><span class="p">)</span><span class="w">
  </span><span class="n">income</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">intercept</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_1</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">data_engineer</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">rnorm</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span><span class="w">
  </span><span class="n">data.frame</span><span class="p">(</span><span class="n">income</span><span class="p">,</span><span class="w"> </span><span class="n">data_engineer</span><span class="p">)}</span><span class="w">
</span></code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">rbinom</code> here is used to randomly generate a dummy variable, with the probability of an observation being 0 (=data scientist) or 1 (=data engineer) being .5. This does not mean that in every single data set we use there will be “50% data engineers” and “50% data scientists” (there values might be 51% and 49%), but that this is true on average in the long run. <code class="language-plaintext highlighter-rouge">rnorm</code> simply draws a random number from the normal distribution, and simulates our error term.</p> <h2 id="running-the-models">Running the models</h2> <p>There are many ways of specifying the code for running the models. My preferred way is to do it in a for loop - I’m that basic.</p> <p>Let’s first define the key parameters of the simulation. <code class="language-plaintext highlighter-rouge">nSims</code> defines the number of repetitions (here set to 1000). We specify a random seed using <code class="language-plaintext highlighter-rouge">set.seed</code> so that you get the exact same results as me when running this simulation. We set up two empty containers (<code class="language-plaintext highlighter-rouge">linearreg</code> and <code class="language-plaintext highlighter-rouge">ttest</code>) to store our model estimates.</p> <p>The simulation itself is executed in the for loop. For every iteration in <code class="language-plaintext highlighter-rouge">nSims</code>, we generate a data set using <code class="language-plaintext highlighter-rouge">make_data()</code> we defined above, run a linear regression and store its coefficient in <code class="language-plaintext highlighter-rouge">linearreg</code>, and run a t-test and store the mean difference in <code class="language-plaintext highlighter-rouge">ttest</code>.</p> <p>Grab a cup of coffee while this is running, it might take a while depending on your computer.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Set number of simulations</span><span class="w">
</span><span class="n">nSims</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="m">1000</span><span class="w">
</span><span class="c1">#Set random seed for reproducibility</span><span class="w">
</span><span class="n">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span><span class="w">
</span><span class="c1">#Set up vectors for storing results</span><span class="w">
</span><span class="n">linearreg</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="n">nSims</span><span class="p">)</span><span class="w">
</span><span class="n">ttest</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">numeric</span><span class="p">(</span><span class="n">nSims</span><span class="p">)</span><span class="w">

</span><span class="c1">#Run the simulation</span><span class="w">
</span><span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="n">nSims</span><span class="p">){</span><span class="w">
  </span><span class="c1">#Simulate the data</span><span class="w">
  </span><span class="n">data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">make_data</span><span class="p">()</span><span class="w">
  
  </span><span class="c1">#Estimate linear regression and store coefficient</span><span class="w">
  </span><span class="n">linear</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="s1">'income ~ data_engineer'</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span><span class="w">
  </span><span class="n">linearreg</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">coef</span><span class="p">(</span><span class="n">linear</span><span class="p">)[</span><span class="m">2</span><span class="p">]</span><span class="w">
    
  </span><span class="c1">#Estimate t-test and store result</span><span class="w">
  </span><span class="n">t_test</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">t.test</span><span class="p">(</span><span class="n">income</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">data_engineer</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">var.equal</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
  </span><span class="n">ttest</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="p">(</span><span class="n">t_test</span><span class="p">[[</span><span class="s2">"estimate"</span><span class="p">]][[</span><span class="s2">"mean in group 1"</span><span class="p">]]</span><span class="o">-</span><span class="n">t_test</span><span class="p">[[</span><span class="s2">"estimate"</span><span class="p">]][[</span><span class="s2">"mean in group 0"</span><span class="p">]])</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <h2 id="examining-simulation-results">Examining simulation results</h2> <p>Now that we have our simulation results, it’s time to examine them and draw a conclusion: can we just use a t-test instead of a linear regression when comparing two means (in the specific situation - ground truth - we defined above)?</p> <p>Let’s first examine the means of all estimates from <code class="language-plaintext highlighter-rouge">linearreg</code> and <code class="language-plaintext highlighter-rouge">ttest</code>. If the t-test is as good as the linear regression, its mean difference should be extremely close to the linear regression coefficient, given that we simulated so many data sets.</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean</span><span class="p">(</span><span class="n">linearreg</span><span class="p">)</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="m">9.999933</span><span class="w">

</span><span class="n">mean</span><span class="p">(</span><span class="n">ttest</span><span class="p">)</span><span class="w">
</span><span class="p">[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="m">9.999933</span><span class="w">
</span></code></pre></div></div> <p>As we see see, the means are identical. How about the histograms of estimates?</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hist</span><span class="p">(</span><span class="n">linearreg</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Histogram of estimates from linear regression"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="p">(</span><span class="s2">"regression coefficient"</span><span class="p">))</span><span class="w">
</span><span class="n">hist</span><span class="p">(</span><span class="n">ttest</span><span class="p">,</span><span class="w"> </span><span class="n">main</span><span class="o">=</span><span class="s2">"Histogram of estimates from t-test"</span><span class="p">,</span><span class="w"> </span><span class="n">xlab</span><span class="o">=</span><span class="p">(</span><span class="s2">"mean difference"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/hist_reg-480.webp 480w, /assets/img/hist_reg-800.webp 800w, /assets/img/hist_reg-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/hist_reg.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/hist_ttest-480.webp 480w, /assets/img/hist_ttest-800.webp 800w, /assets/img/hist_ttest-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/hist_ttest.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>They, too, look completely identical and both look like a normal distribution. If we increase the size of <code class="language-plaintext highlighter-rouge">nSims</code>, they histogram will eventually look exactly like a normal distribution.</p> <p>What does this tell us? Yes, if we have a simple model like this (with only an intercept and one dummy variable and normally distributed errors), linear regression and an independent sample t-test recover the exact same mean difference.</p> <h1 id="beyond-simple-examples-what-else-can-you-do-with-simulations">Beyond simple examples: what else can you do with simulations?</h1> <p>This was, of course, only a very simple example meant to illustrate the workflow of a simulation study. You can do so many cool things with simulations. For example, you could examine if it makes a difference whether you use a linear probability model or logistic regression under various circumstances (e.g., correlations between variables, range of variables, etc.). Spoiler alert: it does, the LPM is bad. Or you could test what the role of sample sizes is for tests of statistical significance. Spoiler alert: the bigger the sample size, the smaller the average p-value.</p> <p>If you are more into prediction models, you could test which model yields the highest accuracy/$F_1$: softmax/multinomial logistic regression, KNN, k-means clustering, etc. The possibilities are endless.</p> <h1 id="in-summary">In summary</h1> <p>Simulations help us understand how statistical models behave under different circumstances, and which model might be better in situation X. We can do this entirely without math by simply running our model(s) of interest on simulated data a large number of times (e.g., 10,000 times) and calculate and plot summary statistics of the results.</p> </body></html>