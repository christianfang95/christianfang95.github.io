<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Christian Fang</title>
<link>https://christianfang95.github.io/blog.html</link>
<atom:link href="https://christianfang95.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>Personal website of Christian Fang</description>
<generator>quarto-1.8.24</generator>
<lastBuildDate>Thu, 24 Nov 2022 23:00:00 GMT</lastBuildDate>
<item>
  <title>There are no “marginally significant” p-values</title>
  <dc:creator>Christian Fang</dc:creator>
  <link>https://christianfang95.github.io/posts/marginally-significant/</link>
  <description><![CDATA[ 





<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Researchers use <img src="https://latex.codecogs.com/png.latex?p">-values in the context of hypothesis testing to decide whether to accept or reject the null hypothesis. The routine goes as follows: before running the analysis/the hypothesis test, we decide on a significance level (or “alpha level”, typically 5% or 0.05) below which we decide to reject the null hypothesis. Next, we run the analysis/hypothesis test, and compute the <img src="https://latex.codecogs.com/png.latex?p">-value. If the <img src="https://latex.codecogs.com/png.latex?p">-value is below the significance level, we reject the null hypothesis: the <img src="https://latex.codecogs.com/png.latex?p">-value is “statistically significant”. If the <img src="https://latex.codecogs.com/png.latex?p">-value is above the significance level, we “fail to reject” the null hypothesis: the <img src="https://latex.codecogs.com/png.latex?p">-value is not statistically significant.</p>
<p>This is illustrated in this nifty pic. If we get a small <img src="https://latex.codecogs.com/png.latex?p">-value we are usually happy (no matter how close it is to 0.05), if we get a big <img src="https://latex.codecogs.com/png.latex?p">-value we cry (and wonder if our paper will ever get published). But what about <img src="https://latex.codecogs.com/png.latex?p">-values that are “hovering” just above 0.05?</p>
<p><img src="https://christianfang95.github.io/posts/marginally-significant/p_value.jpeg" class="image-fluid mx-auto d-block img-fluid"></p>
<p>In many published papers you will find such a “third kind” of <img src="https://latex.codecogs.com/png.latex?p">-value, which is commonly called the “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-value. Alternative names include <img src="https://latex.codecogs.com/png.latex?p">-values that are “trending towards significance”, “approaching significance”, “hovering just above the significance level”, or “almost significant”.</p>
<p>Such “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values, however, simply do not exist. In other words, labeling some <img src="https://latex.codecogs.com/png.latex?p">-values as “marginally significant” is a statistical mistake (which is why I use this term between ” “). Let me tell you why.</p>
</section>
<section id="what-do-people-mean-by-marginally-significant-p-values" class="level1">
<h1>What do people mean by “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values?</h1>
<p>In the null hypothesis significance testing framework, we use the <img src="https://latex.codecogs.com/png.latex?p">-value to decide whether we reject or fail to reject the null. Just like there are only two possible outcomes, there are only two kinds of <img src="https://latex.codecogs.com/png.latex?p">-values: significant ones and non-significant ones. Researchers who claim to have found “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values, thus, essentially claim that there is a some (vaguely/subjectively-defined) subset of non-significant <img src="https://latex.codecogs.com/png.latex?p">-values that one could (or perhaps even should!) still interpret as significant.</p>
<p>The practice to label some non-significant <img src="https://latex.codecogs.com/png.latex?p">-values as “marginally significant” dates back over 75 years ago. I found a paper published in <em>American Sociological Review</em> in <a href="https://www.jstor.org/stable/2087117?seq=3#metadata_info_tab_contents">1946</a> in which the authors refer to “marginally signficiant” <img src="https://latex.codecogs.com/png.latex?p">-values. So, suffice to say, it’s a mistake that people have been making for a very, very long time, and that has become ingrained in statistical practice in many disciplines.</p>
<p>While there is no definition of what a “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-value is supposed to be (because they do not exist in statistical terms), an empirical analysis of psychology studies found that researchers generally seem to define <img src="https://latex.codecogs.com/png.latex?p">-values between 0.05 and 0.10 as “marginally significant”, though some researchers have apparently labeled <img src="https://latex.codecogs.com/png.latex?p">-values as big as 0.18 as “marginally significant” <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797616645672?casa_token=QvY85WkWqlMAAAAA:taL4m6gL85a2ocmUvtWQtkYbe_GZtvSQzA0jZYppTIlgw58cFKEt_SOcbJJlu2wJos54sTGhf7uCtw">(see this excellent article for more details)</a>. This shows that there is little consistency in what is and isn’t supposed to be “marginally significant” - which makes sense, given that it’s a made-up term that you will for good reason not find in any statistics textbook.</p>
<p>As a side note: my suspicion is that researchers speak of “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values only if they ran their analysis and the <img src="https://latex.codecogs.com/png.latex?p">-value turned out to be “disappointingly big”. In other words, researchers claim that a non-significant <img src="https://latex.codecogs.com/png.latex?p">-value is “marginally significant”, so that they can prove themselves right (i.e., they can conclude that their study results are in line with their hypothesis). Thus, researchers use their arbitrary gut feeling to after they conducted the analysis(!) decide that some non-significant <img src="https://latex.codecogs.com/png.latex?p">-values are “marginally significant”.</p>
<p>Such researchers commit two statistical crimes and a philosophy-of-science crime. The first statistical crime is that these researchers apparently alter their <img src="https://latex.codecogs.com/png.latex?%5Calpha">-level post-hoc to fit their narrative (a form of confirmation bias and/or <img src="https://latex.codecogs.com/png.latex?p">-hacking). Remember: the <img src="https://latex.codecogs.com/png.latex?%5Calpha">-level is determined before you run the analysis, and not just changed afterwards. The second statistical crime is that these researchers make a subjective decision which is not backed by statistical theory and invent a whole new (but undefined) class of potential outcomes of a null hypothesis test (i.e., rejecting the null, failing to reject the null, failing to reject but at the same time still somehow rejecting the null).</p>
<p>The philosophy-of-science crime is that, per Popper, we are supposed to try to <em>falsify</em> our hypotheses as stringently as possible, not come up with ever-fancier ways of proving ourselves right all the time. This misunderstanding has led to a detrimental culture in which researchers’ hypotheses are confirmed all the time (<a href="https://journals.sagepub.com/doi/abs/10.1177/25152459211007467">over 90% of the time!</a>), partly because many studies are <img src="https://latex.codecogs.com/png.latex?p">-hacked or because the results of hypothesis tests are bent in such ways that they always “confirm” the study hypotheses, even if the data says otherwise. This is dangerous, as it might give students or the next generation of scientists the impression that the point of science is to prove your own preconceived notions to be correct (which is not the point, of course), or that they “made a mistake” if their <img src="https://latex.codecogs.com/png.latex?p">-value is greater than 0.05 (which is nonsense, of course!)</p>
</section>
<section id="why-do-people-claim-to-have-found-marginally-significant-p-values-if-there-is-no-such-thing" class="level1">
<h1>Why do people claim to have found “marginally significant” p-values if there is no such thing?</h1>
<p>Obviously, I have no idea about what is actually going on in researchers’ heads when they label <img src="https://latex.codecogs.com/png.latex?p">-values as “marginally signficant”, but I have two ideas about where this comes from. The first reason lies in poor education in statistics and a confusion between two competing paradigms for interpreting <img src="https://latex.codecogs.com/png.latex?p">-values. The second reason is the pressure to publish and “be successful” in academia (success as measured by you getting <img src="https://latex.codecogs.com/png.latex?p%20%3C.05">), combined with the fact that papers with significant results are more likely to get published than papers that report “null findings”.</p>
<section id="reason-1-mixing-up-frameworks-for-interpreting-p-values" class="level2">
<h2 class="anchored" data-anchor-id="reason-1-mixing-up-frameworks-for-interpreting-p-values">Reason 1: Mixing up frameworks for interpreting <img src="https://latex.codecogs.com/png.latex?p">-values</h2>
<p>Historically, there were two mutually exclusive frameworks to interpret <img src="https://latex.codecogs.com/png.latex?p">-values: Fisher’s and Neyman’s &amp; Pearson’s.</p>
<p>Fisher intended for <img src="https://latex.codecogs.com/png.latex?p">-values to be interpreted as a continuous measure of the strength of the evidence against the null hypothesis. Under this framework, a <img src="https://latex.codecogs.com/png.latex?p">-value of 0.20 is viewed as weaker evidence against the null than a <img src="https://latex.codecogs.com/png.latex?p">-value of 0.02.</p>
<p>Neyman &amp; Pearson advocated to classify <img src="https://latex.codecogs.com/png.latex?p">-values as either significant or not significant, based on a pre-defined threshold ( <img src="https://latex.codecogs.com/png.latex?%5Calpha"> ). If <img src="https://latex.codecogs.com/png.latex?p%3C%20%5Calpha">, we reject the null hypothesis. If <img src="https://latex.codecogs.com/png.latex?p%20%3E%20%5Calpha">, we fail to reject the null hypothesis.</p>
<p>Our current way of interpreting <img src="https://latex.codecogs.com/png.latex?p">-values is a mix of the two: on the one hand, we apply a decision rule (like in the Neyman-Pearson framework), on the other hand, we use stars to indicate how small a <img src="https://latex.codecogs.com/png.latex?p">-value is: one star for <img src="https://latex.codecogs.com/png.latex?p%20%3C%20.05">, two stars for <img src="https://latex.codecogs.com/png.latex?0.05%20%3C%20p%20%3C%20.01">, and two stars for <img src="https://latex.codecogs.com/png.latex?p%20%3C%20.001">. Some R functions, like <code>lm()</code>, even use a dot ‘.’ for <img src="https://latex.codecogs.com/png.latex?p">-values between 0.1 and 0.05:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lm</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">formula =</span> y <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> x1 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x2 <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> x3, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> data))</span>
<span id="cb1-2"></span>
<span id="cb1-3">Coefficients<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span></span>
<span id="cb1-4">            Estimate Std. Error t value <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">Pr</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">|</span>t<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>)    </span>
<span id="cb1-5">(Intercept)  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.95251</span>    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.03297</span>   <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">89.55</span>   <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-16</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-6">x1          <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.50722</span>    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01847</span>  <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">81.58</span>   <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-16</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-7">x2           <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.81344</span>    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01808</span>   <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">44.99</span>   <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-16</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-8">x3          <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.82236</span>    <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.03950</span>  <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">20.82</span>   <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2e-16</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-9"><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">---</span></span>
<span id="cb1-10">Signif. codes<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span>  <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> ‘<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span>’ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span> ‘<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>’ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span> ‘<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>’ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span> ‘.’ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span> ‘ ’ <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div></div>
<p>Researchers might be confused about the two paradigms and interpret <img src="https://latex.codecogs.com/png.latex?p">-values in a more Fisherian fashion, and not evaluate them vis-a-vis a decision threshold. Or rather: researchers do acknowledge that <img src="https://latex.codecogs.com/png.latex?p">-values should be below the chosen <img src="https://latex.codecogs.com/png.latex?%5Calpha">-level in order to be interpreted as significant, but if the <img src="https://latex.codecogs.com/png.latex?p">-value is - in their subjective perception - “close enough” to 0.05, it is “practically” significant, by only a small margin. A.k.a., the <img src="https://latex.codecogs.com/png.latex?p">-value is “marginally significant”.</p>
<p>Unfortunately, such an interpretation makes no sense. None of the three frameworks allow for the existence of “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values. In Fisher’s framework, there is no hard boundary at which <img src="https://latex.codecogs.com/png.latex?p">-values automatically become “significant”. Per Fisher you would conclude that <img src="https://latex.codecogs.com/png.latex?p=0.049"> and <img src="https://latex.codecogs.com/png.latex?p=0.051"> constitute practically equivalent evidence against the null, but you would not call either “significant” per se. In Neyman-Pearson and our current way of interpreting <img src="https://latex.codecogs.com/png.latex?p">-values, we are interested in whether <img src="https://latex.codecogs.com/png.latex?p%3C%20%5Calpha">. There is no third kind of <img src="https://latex.codecogs.com/png.latex?p">-value that hovers just above our chosen <img src="https://latex.codecogs.com/png.latex?%5Calpha">-level.</p>
</section>
<section id="reason-2-academic-publish-or-perish-environment-and-researchers-disappointment" class="level2">
<h2 class="anchored" data-anchor-id="reason-2-academic-publish-or-perish-environment-and-researchers-disappointment">Reason 2: Academic publish or perish environment and researchers’ disappointment</h2>
<p>Studies in academia take a lot of time to conduct and write up, and oftentimes even longer to get published. Imagine you are a researcher who has spent the last two years (and potentially thousands, if not hundreds of thousands, of euros of tax payers’ money) on a study. You collected the data, ran the analysis, and the <img src="https://latex.codecogs.com/png.latex?p">-value of your hypothesis test is 0.06. The horror! How are you gonna get this published??? You know that journals are way more likely to publish papers that have significant <img src="https://latex.codecogs.com/png.latex?p">-values than papers reporting “null findings”! You were so sure that you were gonna get a significant <img src="https://latex.codecogs.com/png.latex?p">-value!</p>
<p>What do you do?</p>
<p>The best option is, of course, to report the true outcome: the <img src="https://latex.codecogs.com/png.latex?p">-value is above the chosen <img src="https://latex.codecogs.com/png.latex?%5Calpha"> level, so based on the data that you have, there is insufficient evidence to reject the null. No biggie. Alternatively, you could resort to questionable or downright unethical research practices like <img src="https://latex.codecogs.com/png.latex?p">-hacking. Or you could label your result “marginally significant”, implying that “in the right light, if I had a somewhat bigger sample size, if the stars aligned, this would be significant, I swear!”</p>
<p>To be clear, the second option is terrible, don’t do it! The third option is somewhat better, but you should still not do it. For once, you are bending the rules: you shouldn’t willy-nilly change your <img src="https://latex.codecogs.com/png.latex?%5Calpha">-level after running the analysis just because you don’t like the result (that’s not science). Second, you don’t actually know if you would get a “more significant” <img src="https://latex.codecogs.com/png.latex?p">-value if you had more data/if the sample size were bigger.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>There are no “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-values, under any framework for interpreting <img src="https://latex.codecogs.com/png.latex?p">-values. Claiming some effect or <img src="https://latex.codecogs.com/png.latex?p">-value is “marginally significant” is wrong: in the null hypothesis testing framework there are just significant and non-significant <img src="https://latex.codecogs.com/png.latex?p">-values, there is not even a definition of what a “marginally significant” <img src="https://latex.codecogs.com/png.latex?p">-value is supposed to be. Using the term “marginally significant” is disingenuous, and honestly renders the whole affair of using a threshold to determine whether or not to reject the null hypothesis pointless. If you are just going to interpret the results any way you want, why use statistics to begin with?</p>
<p>Either your <img src="https://latex.codecogs.com/png.latex?p">-value is above or below the a priori chosen significance level. It’s that simple.</p>
</section>
<section id="references" class="level1">
<h1>References</h1>
<p>If you want to read more about “marginally signficant” <img src="https://latex.codecogs.com/png.latex?p">-values, check out these excellent papers:</p>
<p>Gibbs, N. M., &amp; Gibbs, S. V. (2015). Misuse of ‘trend’to describe ‘almost significant’ differences in anaesthesia research. <em>British Journal of Anaesthesia</em>, 115(3), 337-339. <a href="https://academic.oup.com/bja/article/115/3/337/312358">Link</a></p>
<p>Johnson, V. E. (2019). Evidence from marginally significant t statistics. <em>The American Statistician</em>, 73(sup1), 129-134. <a href="https://www.tandfonline.com/doi/abs/10.1080/00031305.2018.1518788">Link</a></p>
<p>Lakens, D. (2021). The practical alternative to the p value is the correctly used p value. <em>Perspectives on psychological science</em>, 16(3), 639-648. <a href="https://journals.sagepub.com/doi/abs/10.1177/1745691620958012">Link</a></p>
<p>Pritschet, L., Powell, D., &amp; Horne, Z. (2016). Marginally significant effects as evidence for hypotheses: Changing attitudes over four decades. <em>Psychological science</em>, 27(7), 1036-1042. <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797616645672">Link</a></p>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{fang2022,
  author = {Fang, Christian},
  title = {There Are No “Marginally Significant” p-Values},
  date = {2022-11-25},
  url = {https://christianfang95.github.io/posts/marginally-significant/},
  langid = {en}
}
</code></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-fang2022" class="csl-entry quarto-appendix-citeas">
Fang, Christian. 2022. <span>“There Are No <span>‘Marginally
Significant’</span> p-Values.”</span> November 25, 2022. <a href="https://christianfang95.github.io/posts/marginally-significant/">https://christianfang95.github.io/posts/marginally-significant/</a>.
</div></div></section></div> ]]></description>
  <category>statistics</category>
  <category>p-values</category>
  <guid>https://christianfang95.github.io/posts/marginally-significant/</guid>
  <pubDate>Thu, 24 Nov 2022 23:00:00 GMT</pubDate>
  <media:content url="https://christianfang95.github.io/posts/marginally-significant/posts/marginally-significant/p_value.jpeg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
